{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import scienceplots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mrmr import mrmr_regression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "torch.manual_seed(4000)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "X=pd.read_csv('.\\\\alternative_data_set\\\\X_diesel.csv',header=None)\n",
    "Y=pd.read_csv('.\\\\alternative_data_set\\\\Y3_diesel.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing values\n",
    "X['target_variable']=Y[1]\n",
    "X=X.dropna()\n",
    "X=X.reset_index(drop=True)\n",
    "Y=X.iloc[:,401]\n",
    "X=X.iloc[:,:401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 401)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split and normalisation\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n",
    "\n",
    "#train 0.8\n",
    "#test 0.2\n",
    "\n",
    "#norm\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_train)\n",
    "x_train=scaler_x.transform(x_train)\n",
    "x_test=scaler_x.transform(x_test)\n",
    "\n",
    "scaler_y=StandardScaler()\n",
    "scaler_y.fit(y_train.values.reshape(-1,1))\n",
    "y_train=scaler_y.transform(y_train.values.reshape(-1,1))\n",
    "y_test=scaler_y.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(x_train)\n",
    "y_train=pd.Series(y_train.ravel())\n",
    "\n",
    "x_test=pd.DataFrame(x_test)\n",
    "y_test=pd.Series(y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=mrmr_regression(X=x_train,\n",
    "                                      y=y_train,\n",
    "                                      K=401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert, pandas to loader\n",
    "def make_loader(X,y,batch):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        try:\n",
    "            X = pd.DataFrame(X)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas DataFrame.\")\n",
    "    \n",
    "    if not isinstance(y, pd.Series):\n",
    "        try:\n",
    "            y = pd.Series(y)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas Series.\")        \n",
    "            \n",
    "    x_tensor=torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor=torch.tensor(y.values, dtype=torch.float32)\n",
    "    set_object=TensorDataset(x_tensor,y_tensor)\n",
    "    loader_object=DataLoader(dataset=set_object,batch_size=batch)\n",
    "    return loader_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        \n",
    "        self.linear1=nn.Linear(input_size,4)\n",
    "        self.activation1=nn.ReLU()\n",
    "        self.linear2=nn.Linear(4,4)\n",
    "        self.activation2=nn.ReLU()\n",
    "        self.linear3=nn.Linear(4,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.linear1(x)\n",
    "        x=self.activation1(x)\n",
    "        x=self.linear2(x)\n",
    "        x=self.activation2(x)\n",
    "        x=self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate once\n",
    "def evaluate(Loader, model, loss_fn):\n",
    "    loss_sum=0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X,y) in enumerate(Loader):\n",
    "            pred=model(X)\n",
    "            loss=loss_fn(pred,y.unsqueeze(1))\n",
    "            loss_sum+=loss.item()\n",
    "            \n",
    "    loss_sum/=len(Loader)\n",
    "    \n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_model(model, loader):\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)  # Get model predictions\n",
    "            predictions.extend(outputs.numpy())  # Store predictions\n",
    "            true_values.extend(labels.numpy())  # Store true labels\n",
    "    \n",
    "    # Calculate R^2 score\n",
    "    return r2_score(true_values, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and store all errors =)\n",
    "def train_fn(TrainLoader, TestLoader, model, loss_fn, optimizer,epochs):\n",
    "    train_loss_epochs=[]\n",
    "    test_loss_epochs=[]\n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #train for every example in the dataloader\n",
    "        for X_train,y_train in TrainLoader:\n",
    "            \n",
    "            pred_train=model(X_train)\n",
    "            loss_train=loss_fn(pred_train,y_train.unsqueeze(1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        loss_train_curr_epoch=evaluate(TrainLoader,model,loss_fn)\n",
    "        train_loss_epochs.append(loss_train_curr_epoch)\n",
    "       \n",
    "        loss_test_curr_epoch=evaluate(TestLoader,model,loss_fn)\n",
    "        test_loss_epochs.append(loss_test_curr_epoch)\n",
    "        \n",
    "    return model, train_loss_epochs, test_loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and not store all errors, i will use this one on the building of the tables, will speed up things...\n",
    "def train_fn_no_loss(TrainLoader, model, loss_fn, optimizer,epochs):\n",
    "    model.train() \n",
    "    for epoch in range(epochs):\n",
    "        #train for every example in the dataloader\n",
    "        for X_train,y_train in TrainLoader:\n",
    "            \n",
    "            pred_train=model(X_train)\n",
    "            loss_train=loss_fn(pred_train,y_train.unsqueeze(1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a single epoch\n",
    "def train_one_epoch(TrainLoader, model, loss_fn, optimizer):\n",
    "    model.train() \n",
    "    #train for every example in the dataloader\n",
    "    for X_train,y_train in TrainLoader:\n",
    "            \n",
    "        pred_train=model(X_train)\n",
    "        loss_train=loss_fn(pred_train,y_train.unsqueeze(1))\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stop criterion\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience, min_delta):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.last_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, loss):\n",
    "        if loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "        elif loss > self.last_loss:  # Spike detection\n",
    "            pass  # Do nothing if a spike is detected\n",
    "        else:\n",
    "            self.counter += 1  # Increment if no improvement or no spike\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        \n",
    "        self.last_loss = loss\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and store all errors =)\n",
    "def train_early_stop(TrainLoader, TestLoader, model, loss_fn, optimizer,max_epochs):\n",
    "    train_loss_epochs=[]\n",
    "    test_loss_epochs=[]\n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    early_stopper = EarlyStopper(patience=25, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        #train for every example in the dataloader\n",
    "        model=train_one_epoch(TrainLoader=TrainLoader, model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "    \n",
    "        loss_train_curr_epoch=evaluate(TrainLoader,model,loss_fn)\n",
    "        train_loss_epochs.append(loss_train_curr_epoch)\n",
    "       \n",
    "        loss_test_curr_epoch=evaluate(TestLoader,model,loss_fn)\n",
    "        test_loss_epochs.append(loss_test_curr_epoch)\n",
    "        \n",
    "        if early_stopper.early_stop(loss=loss_train_curr_epoch):        \n",
    "            break\n",
    "        \n",
    "    return model, train_loss_epochs, test_loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and not store errors\n",
    "def train_early_stop_no_loss(TrainLoader, model, loss_fn, optimizer,max_epochs):\n",
    "    model.train() \n",
    "    \n",
    "    early_stopper = EarlyStopper(patience=25, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        #train for every example in the dataloader\n",
    "        model=train_one_epoch(TrainLoader=TrainLoader, model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "       \n",
    "        loss_train_curr_epoch=evaluate(TrainLoader,model,loss_fn)\n",
    "        \n",
    "        if early_stopper.early_stop(loss=loss_train_curr_epoch):             \n",
    "            break\n",
    "        \n",
    "    return model, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple function to initialize parameters, also work as a 'reset' of parameters\n",
    "def ini_model(input,epochs=200):\n",
    "    torch.manual_seed(42)\n",
    "    model=NeuralNetwork(input_size=input)\n",
    "    loss_fn=nn.MSELoss()\n",
    "    optimizer=optim.Adam(model.parameters(),\n",
    "                         lr=0.001,\n",
    "                         weight_decay=0)\n",
    "    return model,loss_fn,optimizer,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_percentage(model, x_test, y_test, scaler_y):\n",
    "    \"\"\"\n",
    "    Calculate the error percentage for a given PyTorch model and test data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model\n",
    "    - x_test: Test features as a pandas DataFrame or a NumPy array\n",
    "    - y_test: True values as a pandas Series/DataFrame or a NumPy array\n",
    "    - scaler_y: The scaler used to normalize the target variable\n",
    "    \n",
    "    Returns:\n",
    "    - percentage_error: Error percentage\n",
    "    \"\"\"\n",
    "    # Ensure the input data is in NumPy array format\n",
    "    if isinstance(x_test, pd.DataFrame):\n",
    "        x_test = x_test.values\n",
    "    if isinstance(y_test, pd.DataFrame) or isinstance(y_test, pd.Series):\n",
    "        y_test = y_test.values\n",
    "\n",
    "    # Convert input data to PyTorch tensors\n",
    "    x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        # Get predictions from the model\n",
    "        predictions_tensor = model(x_test_tensor)\n",
    "    \n",
    "    # Convert predictions to NumPy array\n",
    "    predictions = predictions_tensor.detach().numpy()\n",
    "    \n",
    "    # Unnormalize the predictions and the true values\n",
    "    predictions_unnormalized = scaler_y.inverse_transform(predictions)\n",
    "    y_test_unnormalized = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test_unnormalized, predictions_unnormalized)\n",
    "    \n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Calculate the mean of the true values\n",
    "    mean_true = np.mean(y_test_unnormalized)\n",
    "    \n",
    "    # Calculate the percentage error\n",
    "    percentage_error = (rmse / mean_true) * 100\n",
    "    \n",
    "    return percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN loss plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=make_loader(X=x_train,y=y_train,batch=1000)\n",
    "test_loader=make_loader(X=x_test,y=y_test,batch=1000)\n",
    "\n",
    "model,loss_fn,optimizer,epochs=ini_model(input=x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)\n",
    "#important_idx=pd.Series(mi_scores).sort_values(ascending=False).head(200).index\n",
    "#x_train_selected=x_train[important_idx.sort_values()]\n",
    "#x_test_selected=x_test[important_idx.sort_values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss, test_loss=train_fn(TrainLoader=train_loader,\n",
    "                                      TestLoader=test_loader, \n",
    "                                      model=model, \n",
    "                                      loss_fn=loss_fn, \n",
    "                                      optimizer=optimizer,\n",
    "                                      epochs=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss, test_loss=train_early_stop(TrainLoader=train_loader,\n",
    "                                             TestLoader=test_loader,\n",
    "                                             model=model,\n",
    "                                             loss_fn=loss_fn,\n",
    "                                             optimizer=optimizer,\n",
    "                                             max_epochs=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.224909618817304"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_error_percentage(model,x_test,y_test,scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756183417091007"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2=r2_score_model(model,test_loader)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sqrt(test_loss[2303])/abs(np.mean(y_test)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parou_no=len(train_loss)\n",
    "parou_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(np.arange(len(train_loss)),train_loss,label='train',color='C1')\n",
    "plt.scatter(np.arange(len(test_loss)),test_loss,label='test',color='C0')\n",
    "#plt.axvline(x=parou_no,color='orange',label='early stop')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlim(0,6000)\n",
    "plt.ylim(0,0.15)\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs',fontsize=14)\n",
    "plt.ylabel('MSE',fontsize=14)\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\feature_selec_learning_curve_diff.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN permutation importance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation importance from scikitlearn internally uses the predict function and checks for the presence\n",
    "#of the fit function. if i feed my pytorch model inside a wrapper scikitlearn allows me tu use it's function =)\n",
    "class PyTorchRegressorWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #this function only needs to exhist to fulfill API contract with scikitlearn\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            #convert to numpy as needed\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.to_numpy()\n",
    "\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            predictions = self.model(X_tensor).numpy()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate permutation importance, evaluate on every fold, also stores learning curves...\n",
    "def permutation_importance_loss_nn(X_train,y_train,k_folds):\n",
    "    \n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        try:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas DataFrame.\")\n",
    "    \n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        try:\n",
    "            y_train = pd.Series(y_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas Series.\")        \n",
    "               \n",
    "    kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "\n",
    "    cross_importances=np.zeros((X_train.shape[1],kfold.n_splits))\n",
    "    r2_list=[]\n",
    "    train_loss_fold=[[],[],[],[],[]]\n",
    "    val_loss_fold=[[],[],[],[],[]]\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "        x_train_fold=X_train.iloc[np.sort(train_idx)]\n",
    "        y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "        x_val_fold=X_train.iloc[np.sort(val_idx)]\n",
    "        y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "        \n",
    "        train_loader_fold=make_loader(X=x_train_fold,y=y_train_fold,batch=1000)\n",
    "        test_loader_fold=make_loader(X=x_val_fold,y=y_val_fold,batch=1000)\n",
    "\n",
    "        model,loss_fn,optimizer,epochs=ini_model(input=401) #epochs defined inside function\n",
    "        \n",
    "        model, train_loss_fold[fold], val_loss_fold[fold]=train_early_stop(TrainLoader=train_loader_fold,\n",
    "                                                                            TestLoader=test_loader_fold,\n",
    "                                                                            model=model,\n",
    "                                                                            loss_fn=loss_fn,\n",
    "                                                                            optimizer=optimizer,\n",
    "                                                                            max_epochs=6000)\n",
    "        \n",
    "        # pass model trough wrapper\n",
    "        model_wrapper = PyTorchRegressorWrapper(model=model)\n",
    "\n",
    "        # permutation importance with the wrapper instance\n",
    "        results = permutation_importance(model_wrapper,\n",
    "                                        x_val_fold,\n",
    "                                        y_val_fold,\n",
    "                                        n_repeats=30,\n",
    "                                        random_state=42,\n",
    "                                        n_jobs=4,\n",
    "                                        scoring='neg_mean_squared_error')\n",
    "        \n",
    "        cross_importances[:,fold]=results.importances_mean\n",
    "        \n",
    "        r2=r2_score_model(model,test_loader_fold)\n",
    "        r2_list.append(r2)\n",
    "        \n",
    "    return r2_list, cross_importances, train_loss_fold, val_loss_fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the indexes to slice the n most important features\n",
    "def perm_imp_get_topn_indexes(perm_imp_output,top_n):\n",
    "    \n",
    "    best_n=perm_imp_output.sort_values().head(top_n).index\n",
    "    \n",
    "    return best_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_nn_perm_imp(x_train,y_train,x_test,y_test,step,perm_imp_array,k_folds):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse','epochs','r2_cal','r2_test','r2_cv','r2_cv_std']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for features in tqdm(np.arange(401,399,-step)):\n",
    "        \n",
    "        important_idx=perm_imp_get_topn_indexes(perm_imp_output=perm_imp_array,\n",
    "                                                top_n=features)\n",
    "    \n",
    "        x_train_reduced=x_train[important_idx.sort_values()]\n",
    "        x_test_reduced=x_test[important_idx.sort_values()]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        r2_CV_folds=[]\n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_reduced)):\n",
    "        \n",
    "            x_train_fold=x_train_reduced.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train_reduced.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            train_loader_fold=make_loader(X=x_train_fold,y=y_train_fold,batch=1000)\n",
    "            val_loader_fold=make_loader(X=x_val_fold,y=y_val_fold,batch=1000)\n",
    "\n",
    "            model,loss_fn,optimizer, _ =ini_model(input=features)#epochs defined inside function\n",
    "           \n",
    "            model,_ =train_early_stop_no_loss(TrainLoader=train_loader_fold,\n",
    "                                           model=model,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           max_epochs=6000)\n",
    "            \n",
    "            train_loss_single_fold=evaluate(Loader=train_loader_fold, model=model, loss_fn=loss_fn)\n",
    "            val_loss_single_fold=evaluate(Loader=val_loader_fold, model=model, loss_fn=loss_fn)\n",
    "            single_fold_val=r2_score_model(model,val_loader_fold)\n",
    "            \n",
    "            r2_CV_folds.append(single_fold_val)\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "        train_loader=make_loader(X=x_train_reduced,y=y_train,batch=1000)\n",
    "        test_loader=make_loader(X=x_test_reduced,y=y_test,batch=1000)\n",
    "\n",
    "        model,loss_fn,optimizer, _ =ini_model(input=features) #definedinside function\n",
    "        model, epoch=train_early_stop_no_loss(TrainLoader=train_loader_fold,\n",
    "                                           model=model,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           max_epochs=6000)\n",
    "                \n",
    "        train_loss=evaluate(Loader=train_loader, model=model, loss_fn=loss_fn)\n",
    "        val_loss=evaluate(Loader=test_loader, model=model, loss_fn=loss_fn)\n",
    "        train_loss_r2=r2_score_model(model,train_loader)\n",
    "        test_loss_r2=r2_score_model(model,test_loader)\n",
    "        \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        avg_CV_r2=np.mean(r2_CV_folds)\n",
    "        std_CV_r2=np.std(r2_CV_folds)\n",
    "        \n",
    "        #columns=['train mse','train std','val mse','val std','calibration mse','test mse','epochs','r2_cal','r2_test','r2_cv','r2_cv_std']\n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                val_loss,\n",
    "                                epoch,\n",
    "                                train_loss_r2,\n",
    "                                test_loss_r2,\n",
    "                                avg_CV_r2,\n",
    "                                std_CV_r2,]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check consistency by intersection\n",
    "def check_intersections(df,top_n):\n",
    "    col=df.columns\n",
    "    matrix=np.zeros((5,5),dtype=float)\n",
    "    top_idx=[]\n",
    "    for i in range(1,6):\n",
    "        top_idx.append(set(perm_imp_get_topn_indexes(perm_imp_output=df['fold'+str(i)],top_n=top_n)))\n",
    "        \n",
    "    for i in range(0,5):\n",
    "        for j in range(0,5):\n",
    "            if j<=j:\n",
    "                intersec_acc=len(top_idx[i] & top_idx[j])/top_n\n",
    "                matrix[i,j]=intersec_acc\n",
    "                matrix[j,i]=intersec_acc\n",
    "    #eturn top_idx\n",
    "    return pd.DataFrame(matrix, index=col, columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN permutation importance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list,importances,train_loss_list,val_loss_list=permutation_importance_loss_nn(X_train=x_train,\n",
    "                                                                      y_train=y_train,\n",
    "                                                                      k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing necessary, assume the correct ranking of each feature is the median value among folds...\n",
    "importance_rank=pd.DataFrame(importances).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check consistency by intersection\n",
    "check_intersections(importance_rank_named,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = build_table_nn_perm_imp(x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                    step=10,\n",
    "                    perm_imp_array=importance_overall_rank,\n",
    "                    k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'table_dataframe_NN_permI_150_to_1')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\table_dataframe_NN_permI.csv')\n",
    "df2=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\table_dataframe_NN_permI_150_to_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary for correct plotting\n",
    "b=np.arange(150,1,-10)\n",
    "a=np.arange(401,150,-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(a, df1['calibration mse'][::1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(b, df2['calibration mse'][::10], marker='s', s=25, color='C1', alpha=0.7)\n",
    "\n",
    "plt.scatter(a, df1['test mse'][::1], marker='s', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.scatter(b, df2['test mse'][::10], marker='s', s=25, color='C0', alpha=0.7)\n",
    "\n",
    "plt.errorbar(a, df1['val mse'][::1], yerr=df1['val std'][::1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(b, df2['val mse'][::10], yerr=df2['val std'][::10], fmt='^', markersize=5, capsize=2, color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=18)\n",
    "plt.ylabel('MSE', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=18)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\ANN_PI.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topX=101\n",
    "important_idx=perm_imp_get_topn_indexes(perm_imp_output=importance_overall_rank,\n",
    "                                        top_n=topX)\n",
    "    \n",
    "x_train_important=x_train[important_idx.sort_values()]\n",
    "x_test_important=x_test[important_idx.sort_values()]\n",
    "\n",
    "train_loader_important=make_loader(x_train_important,y_train,100)\n",
    "test_loader_important=make_loader(x_test_important,y_test,100)\n",
    "\n",
    "model,loss_fn,optimizer,epochs=ini_model(input=topX,epochs=200)\n",
    "model, train_loss, test_loss=train_early_stop(TrainLoader=train_loader_important,\n",
    "                                                                            TestLoader=test_loader_important,\n",
    "                                                                            model=model,\n",
    "                                                                            loss_fn=loss_fn,\n",
    "                                                                            optimizer=optimizer,\n",
    "                                                                            max_epochs=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_loss)),train_loss,label='cal loss')\n",
    "plt.plot(np.arange(len(test_loss)),test_loss,label='test loss')\n",
    "plt.legend()\n",
    "plt.xlim(-10,2000)\n",
    "plt.ylim(0,0.03)\n",
    "plt.grid()\n",
    "plt.xlabel('epocs')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN permutation importance loss on kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_vals,importances,train_loss_list,val_loss_list=permutation_importance_loss_nn(X_train=x_train,\n",
    "                                                                      y_train=y_train,\n",
    "                                                                      k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss plots on different folds\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))  # 3 rows, 2 columns\n",
    "\n",
    "# flat so i can use indexing\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot on subplot i\n",
    "    axs_flat[i].plot(np.arange(len(train_loss_list[i])), train_loss_list[i], label='Train')\n",
    "    axs_flat[i].plot(np.arange(len(val_loss_list[i])), val_loss_list[i], label='Validation')\n",
    "    axs_flat[i].legend()\n",
    "    axs_flat[i].set_title(f'Series {i+1}')\n",
    "    axs_flat[i].set_ylim([0, 0.8])\n",
    "\n",
    "# Hide the last subplot as it's unused\n",
    "axs_flat[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN minimum redundance maximum relevance (mRMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_mrmr_nn(x_train,y_train,x_test,y_test,step,k_folds):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse','epochs']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    selected_features=mrmr_regression(X=x_train,\n",
    "                                      y=y_train,\n",
    "                                      K=401)\n",
    "\n",
    "    for features in tqdm(range(401, 1, -step)):\n",
    "        \n",
    "        important_idx=selected_features[0:features]\n",
    "    \n",
    "        important_idx.sort()\n",
    "    \n",
    "        x_train_selected=x_train[important_idx]\n",
    "        x_test_selected=x_test[important_idx]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train)):\n",
    "        \n",
    "            x_train_fold=x_train_selected.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train_selected.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            train_loader_fold=make_loader(X=x_train_fold,y=y_train_fold,batch=1000)\n",
    "            val_loader_fold=make_loader(X=x_val_fold,y=y_val_fold,batch=1000)\n",
    "\n",
    "            model,loss_fn,optimizer, _ =ini_model(input=features)#epochs defined inside function\n",
    "\n",
    "            model,_ =train_early_stop_no_loss(TrainLoader=train_loader_fold,\n",
    "                                           model=model,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           max_epochs=6000)\n",
    "            \n",
    "            train_loss_single_fold=evaluate(Loader=train_loader_fold, model=model, loss_fn=loss_fn)\n",
    "            val_loss_single_fold=evaluate(Loader=val_loader_fold, model=model, loss_fn=loss_fn)\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "        train_loader=make_loader(X=x_train_selected,y=y_train,batch=1000)\n",
    "        test_loader=make_loader(X=x_test_selected,y=y_test,batch=1000)\n",
    "\n",
    "        model,loss_fn,optimizer, _ =ini_model(input=features) #definedinside function\n",
    "        model, epoch=train_early_stop_no_loss(TrainLoader=train_loader_fold,\n",
    "                                           model=model,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           max_epochs=6000)\n",
    "                \n",
    "        train_loss=evaluate(Loader=train_loader, model=model, loss_fn=loss_fn)\n",
    "        val_loss=evaluate(Loader=test_loader, model=model, loss_fn=loss_fn)\n",
    "        \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                val_loss,\n",
    "                                epoch]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mrmr_nn(x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                    step=10,\n",
    "                    k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\table_dataframe_NN_mrmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table\n",
    "\n",
    "new_index = range(401, 1, -10)\n",
    "table.index = new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-1], table['calibration mse'][::-1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-1], table['test mse'][::-1], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=18)\n",
    "plt.ylabel('MSE', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=18)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\NN_mrmr.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'table_dataframe_NN_mrmr')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def build_table_mi_nn(x_train, y_train, x_test, y_test, step, k_folds):\n",
    "    set_seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    # Here I used the terms calibration and train somewhat interchangeably\n",
    "    # The idea is that the complete train set without fold separation to be called calibration\n",
    "    # The fold used to generate the model is train and the fold used to validate is validation...\n",
    "    columns = ['train mse', 'train std', 'val mse', 'val std', 'calibration mse', 'test mse', 'epochs']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    mi_scores = mutual_info_regression(x_train, y_train, n_neighbors=3)\n",
    "\n",
    "    for features in tqdm(range(401, 20, -step)):\n",
    "        important_idx = pd.Series(mi_scores).sort_values(ascending=False).head(features).index\n",
    "\n",
    "        x_train_selected = x_train[important_idx.sort_values()]\n",
    "        x_test_selected = x_test[important_idx.sort_values()]\n",
    "\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train)):\n",
    "            x_train_fold = x_train_selected.iloc[np.sort(train_idx)]\n",
    "            y_train_fold = y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold = x_train_selected.iloc[np.sort(val_idx)]\n",
    "            y_val_fold = y_train.iloc[np.sort(val_idx)]\n",
    "\n",
    "            train_loader_fold = make_loader(X=x_train_fold, y=y_train_fold, batch=1000)\n",
    "            val_loader_fold = make_loader(X=x_val_fold, y=y_val_fold, batch=1000)\n",
    "\n",
    "            model, loss_fn, optimizer, _ = ini_model(input=features)  # epochs defined inside function\n",
    "\n",
    "            model, _ = train_early_stop_no_loss(TrainLoader=train_loader_fold,\n",
    "                                                model=model,\n",
    "                                                loss_fn=loss_fn,\n",
    "                                                optimizer=optimizer,\n",
    "                                                max_epochs=6000)\n",
    "\n",
    "            train_loss_single_fold = evaluate(Loader=train_loader_fold, model=model, loss_fn=loss_fn)\n",
    "            val_loss_single_fold = evaluate(Loader=val_loader_fold, model=model, loss_fn=loss_fn)\n",
    "\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "\n",
    "        train_loader = make_loader(X=x_train_selected, y=y_train, batch=1000)\n",
    "        test_loader = make_loader(X=x_test_selected, y=y_test, batch=1000)\n",
    "\n",
    "        model, loss_fn, optimizer, _ = ini_model(input=features)  # defined inside function\n",
    "        model, epoch = train_early_stop_no_loss(TrainLoader=train_loader,\n",
    "                                                model=model,\n",
    "                                                loss_fn=loss_fn,\n",
    "                                                optimizer=optimizer,\n",
    "                                                max_epochs=6000)\n",
    "\n",
    "        train_loss = evaluate(Loader=train_loader, model=model, loss_fn=loss_fn)\n",
    "        val_loss = evaluate(Loader=test_loader, model=model, loss_fn=loss_fn)\n",
    "\n",
    "        # ['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold = np.mean(train_mse_fold)\n",
    "        std_loss_train_fold = np.std(train_mse_fold)\n",
    "        avg_loss_val_fold = np.mean(val_mse_fold)\n",
    "        std_loss_val_fold = np.std(val_mse_fold)\n",
    "\n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                val_loss,\n",
    "                                epoch]\n",
    "\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mi_nn(x_train=x_train,\n",
    "                  y_train=y_train,\n",
    "                  x_test=x_test,\n",
    "                  y_test=y_test,\n",
    "                  step=10,\n",
    "                  k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'NN_MI.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=np.arange(401, 20, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\NN_MI.csv')\n",
    "table.index=list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index, table['calibration mse'], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index, table['test mse'], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index, table['val mse'], yerr=table['val std'], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\NN_MI.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS permutation importance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate permutation importance, evaluate on every fold, also stores learning curves...\n",
    "def permutation_importance_pls(X_train,y_train,k_folds,latent_variables):\n",
    "    \n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        try:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas DataFrame.\")\n",
    "    \n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        try:\n",
    "            y_train = pd.Series(y_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas Series.\")        \n",
    "               \n",
    "    kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "\n",
    "    cross_importances=np.zeros((x_train.shape[1],kfold.n_splits))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "        x_train_fold=X_train.iloc[np.sort(train_idx)]\n",
    "        y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "        x_val_fold=X_train.iloc[np.sort(val_idx)]\n",
    "        y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "        \n",
    "        pls=PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train_fold,y_train_fold)\n",
    "        \n",
    "        results = permutation_importance(pls,\n",
    "                                        x_val_fold,\n",
    "                                        y_val_fold,\n",
    "                                        n_repeats=30,\n",
    "                                        random_state=42,\n",
    "                                        n_jobs=4,\n",
    "                                        scoring='neg_mean_squared_error')\n",
    "        \n",
    "        cross_importances[:,fold]=results.importances_mean\n",
    "        \n",
    "    return cross_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_pls(x_train, y_train, x_test, y_test, step, perm_imp_array, k_folds, latent_variables):\n",
    "    columns = ['train mse', 'train std', 'val mse', 'val std', 'calibration mse', 'test mse',\n",
    "               'r2_cal', 'r2_test', 'r2_cv', 'r2_cv_std']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for features in np.arange(X.shape[1], 25, -step):\n",
    "        important_idx = perm_imp_get_topn_indexes(perm_imp_output=perm_imp_array, top_n=features)\n",
    "\n",
    "        x_train_reduced = x_train[important_idx.sort_values()]\n",
    "        x_test_reduced = x_test[important_idx.sort_values()]\n",
    "\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "        r2_CV_folds = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_reduced)):\n",
    "            x_train_fold = x_train_reduced.iloc[np.sort(train_idx)]\n",
    "            y_train_fold = y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold = x_train_reduced.iloc[np.sort(val_idx)]\n",
    "            y_val_fold = y_train.iloc[np.sort(val_idx)]\n",
    "\n",
    "            pls = PLSRegression(n_components=latent_variables)\n",
    "            pls.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "            train_loss_single_fold = mean_squared_error(y_train_fold, pls.predict(x_train_fold))\n",
    "            val_loss_single_fold = mean_squared_error(y_val_fold, pls.predict(x_val_fold))\n",
    "            single_fold_val = r2_score(y_val_fold, pls.predict(x_val_fold))\n",
    "\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "            r2_CV_folds.append(single_fold_val)\n",
    "\n",
    "        pls = PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train_reduced, y_train)\n",
    "\n",
    "        train_loss = mean_squared_error(y_train, pls.predict(x_train_reduced))\n",
    "        test_loss = mean_squared_error(y_test, pls.predict(x_test_reduced))\n",
    "        train_loss_r2 = r2_score(y_train, pls.predict(x_train_reduced))\n",
    "        test_loss_r2 = r2_score(y_test, pls.predict(x_test_reduced))\n",
    "\n",
    "        avg_loss_train_fold = np.mean(train_mse_fold)\n",
    "        std_loss_train_fold = np.std(train_mse_fold)\n",
    "        avg_loss_val_fold = np.mean(val_mse_fold)\n",
    "        std_loss_val_fold = np.std(val_mse_fold)\n",
    "        avg_CV_r2 = np.mean(r2_CV_folds)\n",
    "        std_CV_r2 = np.std(r2_CV_folds)\n",
    "\n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss,\n",
    "                                train_loss_r2,\n",
    "                                test_loss_r2,\n",
    "                                avg_CV_r2,\n",
    "                                std_CV_r2]\n",
    "\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS permutation importance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_used=[]\n",
    "train_list=[]\n",
    "test_list=[]\n",
    "cv_list=[]\n",
    "for i in np.arange(1,51,1):\n",
    "    \n",
    "    pls=PLSRegression(n_components=i)\n",
    "    pls.fit(x_train,y_train)\n",
    "    pred_train=pls.predict(x_train)\n",
    "    pred_test=pls.predict(x_test)\n",
    "    train_mse=mean_squared_error(y_train,pred_train)\n",
    "    test_mse=mean_squared_error(y_test,pred_test)\n",
    "    \n",
    "    cv_scores = cross_val_score(pls, x_train, y_train, scoring='neg_mean_squared_error')\n",
    "    # Since scores are negative, take the absolute value to get the mean squared error\n",
    "    cv_mse = -cv_scores\n",
    "\n",
    "    cv_list.append(cv_mse.mean())\n",
    "    train_list.append(train_mse)\n",
    "    test_list.append(test_mse)\n",
    "    components_used.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('science')\n",
    "\n",
    "# Creating the figure with a specified size\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting the data\n",
    "ax.plot(components_used, train_list, label='train', color='C1', linewidth=1.5)\n",
    "ax.plot(components_used, test_list, label='test', color='C0', linewidth=1.5)\n",
    "ax.plot(components_used, cv_list, label='CV', color='C2', linewidth=1.5)\n",
    "\n",
    "# Adding legend\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "# Setting the title and axis labels\n",
    "#ax.set_title('PLSR Error Over Components')\n",
    "ax.set_xlabel('Components',fontsize=14)\n",
    "ax.set_ylabel('MSE',fontsize=14)\n",
    "\n",
    "# Setting y-axis limits\n",
    "ax.set_ylim(0, 0.6)\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensuring the ticks are more visible\n",
    "\n",
    "\n",
    "# Saving the figure in both vector and high-resolution raster formats\n",
    "#fig.savefig('pls_error_over_components.pdf', format='pdf', bbox_inches='tight')\n",
    "#fig.savefig('pls_error_over_components.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\pls_error_over_components.pdf', format='pdf', bbox_inches='tight')\n",
    "#fig.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\pls_error_over_components.png', format='png', dpi=300, bbox_inches='tight')\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_pls=permutation_importance_pls(X_train=x_train,\n",
    "                                           y_train=y_train,\n",
    "                                           k_folds=5,\n",
    "                                           latent_variables=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importance_rank=pd.DataFrame(importances_pls).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank_pls=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_intersections(importance_rank_named,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = build_table_pls(x_train=x_train,\n",
    "                        y_train=y_train,\n",
    "                       x_test=x_test,\n",
    "                       y_test=y_test,\n",
    "                       step=10,\n",
    "                       perm_imp_array=importance_overall_rank_pls,\n",
    "                       k_folds=5,\n",
    "                       latent_variables=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-1], table['calibration mse'][::-1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-1], table['test mse'][::-1], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_PI_25.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_mutual_info_PLS(x_train,y_train,x_test,y_test,step,k_folds,latent_variables):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)\n",
    "\n",
    "    for features in np.arange(X.shape[1],20,-step):\n",
    "        \n",
    "        important_idx=pd.Series(mi_scores).sort_values(ascending=False).head(features).index\n",
    "    \n",
    "        x_train=x_train[important_idx.sort_values()]\n",
    "        x_test=x_test[important_idx.sort_values()]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train)):\n",
    "        \n",
    "            x_train_fold=x_train.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            pls=PLSRegression(n_components=latent_variables)\n",
    "            pls.fit(x_train_fold,y_train_fold)\n",
    "            \n",
    "            train_loss_single_fold=mean_squared_error(y_train_fold,pls.predict(x_train_fold))\n",
    "            val_loss_single_fold=mean_squared_error(y_val_fold,pls.predict(x_val_fold))\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "\n",
    "        pls=PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train,y_train)\n",
    "        \n",
    "        train_loss=mean_squared_error(y_train,pls.predict(x_train))\n",
    "        test_loss=mean_squared_error(y_test,pls.predict(x_test))\n",
    "    \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mutual_info_PLS(x_train=x_train,\n",
    "                                  y_train=y_train,\n",
    "                                  x_test=x_test,\n",
    "                                  y_test=y_test,\n",
    "                                  step=10,\n",
    "                                  k_folds=5,\n",
    "                                  latent_variables=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-1], table['calibration mse'][::-1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-1], table['test mse'][::-1], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_MI_fixed_15.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_pls_mrmr(x_train, y_train, x_test, y_test, step, k_folds, latent_variables):\n",
    "    columns = ['train_mse', 'train_std', 'val_mse', 'val_std', 'calibration_mse', 'test_mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    selected_features = mrmr_regression(X=x_train, y=y_train, K=401)\n",
    "    \n",
    "    for features in np.arange(401, 20, -step):\n",
    "        important_idx = selected_features[0:features]\n",
    "        \n",
    "        x_train_selected = x_train[important_idx]\n",
    "        x_test_selected = x_test[important_idx]\n",
    "        \n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_selected)):\n",
    "            x_train_fold = x_train_selected.iloc[np.sort(train_idx)]\n",
    "            y_train_fold = y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold = x_train_selected.iloc[np.sort(val_idx)]\n",
    "            y_val_fold = y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            pls = PLSRegression(n_components=latent_variables)\n",
    "            pls.fit(x_train_fold, y_train_fold)\n",
    "            \n",
    "            train_loss_single_fold = mean_squared_error(y_train_fold, pls.predict(x_train_fold))\n",
    "            val_loss_single_fold = mean_squared_error(y_val_fold, pls.predict(x_val_fold))\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "        pls = PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train_selected, y_train)\n",
    "        \n",
    "        train_loss = mean_squared_error(y_train, pls.predict(x_train_selected))\n",
    "        test_loss = mean_squared_error(y_test, pls.predict(x_test_selected))\n",
    "        \n",
    "        avg_loss_train_fold = np.mean(train_mse_fold)\n",
    "        std_loss_train_fold = np.std(train_mse_fold)\n",
    "        avg_loss_val_fold = np.mean(val_mse_fold)\n",
    "        std_loss_val_fold = np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code yielded me exactly the same values the library returned.\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_regression\n",
    "def custom_mrmr(X,y,K):\n",
    "    # inputs:\n",
    "    #    X: pandas.DataFrame, features\n",
    "    #    y: pandas.Series, target variable\n",
    "    #    K: number of features to select\n",
    "\n",
    "    # compute F-statistics and correlations\n",
    "    F = pd.Series(f_regression(X, y)[0], index = X.columns)\n",
    "    corr = X.corr().abs().clip(.00001) # minimum value of correlation set to .00001 (to avoid division by zero)\n",
    "\n",
    "    # initialize list of selected features and list of excluded features\n",
    "    selected = []\n",
    "    not_selected = list(X.columns)\n",
    "\n",
    "    # repeat K times: \n",
    "    # compute FCQ score for all the features that are currently excluded,\n",
    "    # then find the best one, add it to selected, and remove it from not_selected\n",
    "    for i in range(K):\n",
    "        \n",
    "        # compute FCQ score for all the (currently) excluded features (this is Formula 2)\n",
    "        score = F.loc[not_selected] / corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001)\n",
    "        \n",
    "        # find best feature, add it to selected and remove it from not_selected\n",
    "        best = score.index[score.argmax()]\n",
    "        selected.append(best)\n",
    "        not_selected.remove(best)\n",
    "    return selected\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = build_table_pls_mrmr(x_train=x_train,\n",
    "                             y_train=y_train,\n",
    "                             x_test=x_test,\n",
    "                             y_test=y_test,  \n",
    "                             step=10,\n",
    "                             k_folds=5,\n",
    "                             latent_variables=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-1], table['calibration_mse'][::-1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-1], table['test_mse'][::-1], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-1], table['val_mse'][::-1], yerr=table['val_std'][::-1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_mrmr_fixed_15.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_mutual_info_pls(x_train,y_train,x_test,y_test,step,k_folds,latent_variables):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)\n",
    "\n",
    "    for features in np.arange(401,150,-step):\n",
    "        \n",
    "        important_idx=pd.Series(mi_scores).sort_values(ascending=False).head(features).index\n",
    "    \n",
    "        x_train=x_train[important_idx.sort_values()]\n",
    "        x_test=x_test[important_idx.sort_values()]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train)):\n",
    "        \n",
    "            x_train_fold=x_train.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            pls=PLSRegression(n_components=latent_variables)\n",
    "            pls.fit(x_train_fold,y_train_fold)\n",
    "            \n",
    "            train_loss_single_fold=mean_squared_error(y_train_fold,pls.predict(x_train_fold))\n",
    "            val_loss_single_fold=mean_squared_error(y_val_fold,pls.predict(x_val_fold))\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "\n",
    "        pls=PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train,y_train)\n",
    "        \n",
    "        train_loss=mean_squared_error(y_train,pls.predict(x_train))\n",
    "        test_loss=mean_squared_error(y_test,pls.predict(x_test))\n",
    "    \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mutual_info_pls(x_train=x_train,\n",
    "                                  y_train=y_train,\n",
    "                                  x_test=x_test,\n",
    "                                  y_test=y_test,\n",
    "                                  step=1,\n",
    "                                  k_folds=5,\n",
    "                                  latent_variables=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV MSE', color='green', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['calibration mse'][::-1], yerr=0, fmt='s', markersize=5, label='Calibration MSE', color='red', alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['test mse'][::-1], yerr=0, fmt='d', markersize=5, label='Test MSE', color='orange', alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top x features', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14)\n",
    "plt.title('MSE and Variance over top n features', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4)\n",
    "plt.ylim(0.01,0.2)\n",
    "plt.gca().invert_xaxis()  # Keep the x-axis inverted\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS mrmr best n_components for top_n variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_mrmr_find_best(x_train, y_train, x_test, y_test, step, k_folds):\n",
    "    columns = ['top_n', 'CV_mean', 'CV_std', 'train', 'test mse', 'n_components']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "   \n",
    "    selected_features = mrmr_regression(X=x_train, y=y_train, K=401)\n",
    "   \n",
    "    for features in tqdm(range(401, 20, -step)):\n",
    "        important_idx = selected_features[:features]\n",
    "       \n",
    "        x_train_important = x_train.iloc[:, important_idx].sort_index(axis=1)\n",
    "        x_test_important = x_test.iloc[:, important_idx].sort_index(axis=1)\n",
    "       \n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "       \n",
    "        best_cv_mean = np.inf\n",
    "        best_cv_std = 0\n",
    "        best_n_components = 0\n",
    "       \n",
    "        max_components = min(features, 50)  # Limit the maximum number of components\n",
    "       \n",
    "        for latent_variables in range(1, max_components + 1):\n",
    "            val_mse_fold = []\n",
    "           \n",
    "            for train_idx, val_idx in kfold.split(x_train_important):\n",
    "                x_train_fold = x_train_important.iloc[train_idx]\n",
    "                y_train_fold = y_train.iloc[train_idx]\n",
    "                x_val_fold = x_train_important.iloc[val_idx]\n",
    "                y_val_fold = y_train.iloc[val_idx]\n",
    "               \n",
    "                pls = PLSRegression(n_components=latent_variables)\n",
    "                pls.fit(x_train_fold, y_train_fold)\n",
    "               \n",
    "                val_loss_single_fold = mean_squared_error(y_val_fold, pls.predict(x_val_fold))\n",
    "                val_mse_fold.append(val_loss_single_fold)\n",
    "           \n",
    "            avg_loss_val_fold = np.mean(val_mse_fold)\n",
    "            std_loss_val_fold = np.std(val_mse_fold)\n",
    "           \n",
    "            if avg_loss_val_fold < best_cv_mean:\n",
    "                best_cv_mean = avg_loss_val_fold\n",
    "                best_cv_std = std_loss_val_fold\n",
    "                best_n_components = latent_variables\n",
    "               \n",
    "        pls = PLSRegression(n_components=best_n_components)\n",
    "        pls.fit(x_train_important, y_train)\n",
    "       \n",
    "        train_loss = mean_squared_error(y_train, pls.predict(x_train_important))\n",
    "        test_loss = mean_squared_error(y_test, pls.predict(x_test_important))\n",
    "       \n",
    "        stored.loc[features] = [features, best_cv_mean, best_cv_std, train_loss, test_loss, best_n_components]\n",
    "       \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pls_mrmr_find_best(x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                    step=10,\n",
    "                    k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'table_top_n__best_n_components_pls_mrmr_diff.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"C:\\\\Users\\\\lucas\\\\Downloads\\\\table_top_n__best_n_components_pls_mrmr.csv\")\n",
    "df2=pd.read_csv(\"C:\\\\Users\\\\lucas\\\\Downloads\\\\table_top_n__best_n_components_pls_mrmr_150_to_1.csv\")\n",
    "table=pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\table_top_n__best_n_components_pls_mrmr_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table['top_n'], table['train'], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table['top_n'], table['test mse'], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table['top_n'], table['CV_mean'], yerr=table['CV_std'], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=18)\n",
    "plt.ylabel('MSE', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=18)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_mrmr_variable.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(table['top_n'], table['n_components'], color='C0', marker='o')\n",
    "\n",
    "\n",
    "plt.ylim(0,50)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.ylabel('Best Number of Latent Variables',fontsize=24)\n",
    "plt.xlabel('Top Ranking Features',fontsize=24)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\best_num_components_example.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison of most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imp(X,important,top_n):\n",
    "    features=np.arange(X.shape[1])\n",
    "    features=pd.Series(features).sort_values()\n",
    "    \n",
    "    best_n=perm_imp_get_topn_indexes(important,top_n)\n",
    "    true_false=features.isin(best_n)\n",
    "    return true_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN perm importance\n",
    "r2_a,importances,train_loss_list,val_loss_list=permutation_importance_loss_nn(X_train=x_train,\n",
    "                                                                      y_train=y_train,\n",
    "                                                                      k_folds=5)\n",
    "importance_rank=pd.DataFrame(importances).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank_nn=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pls perm importance\n",
    "importances_pls=permutation_importance_pls(X_train=x_train,\n",
    "                                           y_train=y_train,\n",
    "                                           k_folds=5,\n",
    "                                           latent_variables=15)\n",
    "importance_rank=pd.DataFrame(importances_pls).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank_pls=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm perm imp\n",
    "importances_svm=permutation_importance_svm(X_train=x_train,\n",
    "                                           y_train=y_train,\n",
    "                                           k_folds=5)\n",
    "importance_rank=pd.DataFrame(importances_svm).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank_svm=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\laohuaYM_noAvg(2).csv',header=None,skiprows=1)\n",
    "\n",
    "df_sorted = df.sort_values(by=1845)\n",
    "\n",
    "train_df = pd.DataFrame(columns=df.columns)\n",
    "test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if (i % 5) == 4:  # Adding every 5th row to the test_df\n",
    "        test_df = pd.concat([test_df, df.iloc[[i]]], ignore_index=True)\n",
    "    else:  # add other rows train\n",
    "        train_df = pd.concat([train_df, df.iloc[[i]]], ignore_index=True)\n",
    "\n",
    "x_train = train_df.iloc[:, :1845]\n",
    "y_train = train_df.iloc[:, 1845]\n",
    "x_test = test_df.iloc[:, :1845]\n",
    "y_test = test_df.iloc[:, 1845]\n",
    "\n",
    "x_train = pd.DataFrame(x_train)\n",
    "y_train = pd.Series(y_train.ravel())\n",
    "\n",
    "x_test = pd.DataFrame(x_test)\n",
    "y_test = pd.Series(y_test.ravel())\n",
    "\n",
    "x_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "x_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#mrmr\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m selected_features_mrmr\u001b[38;5;241m=\u001b[39m\u001b[43mmrmr_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m mrmr_rank\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(selected_features_mrmr)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m mrmr_rank\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries(mrmr_rank\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mrmr\\pandas.py:245\u001b[0m, in \u001b[0;36mmrmr_regression\u001b[1;34m(X, y, K, relevance, redundancy, denominator, cat_features, cat_encoding, only_same_domain, return_scores, n_jobs, show_progress)\u001b[0m\n\u001b[0;32m    242\u001b[0m relevance_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m: X, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y}\n\u001b[0;32m    243\u001b[0m redundancy_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m: X}\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmrmr_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelevance_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredundancy_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredundancy_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mrelevance_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelevance_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredundancy_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredundancy_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdenominator_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenominator_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_same_domain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_same_domain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mreturn_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mrmr\\main.py:98\u001b[0m, in \u001b[0;36mmrmr_base\u001b[1;34m(K, relevance_func, redundancy_func, relevance_args, redundancy_args, denominator_func, only_same_domain, return_scores, show_progress)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmrmr_base\u001b[39m(K, relevance_func, redundancy_func,\n\u001b[0;32m     45\u001b[0m               relevance_args\u001b[38;5;241m=\u001b[39m{}, redundancy_args\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m     46\u001b[0m               denominator_func\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean, only_same_domain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m               return_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"General function for mRMR algorithm.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        List of selected features.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     relevance \u001b[38;5;241m=\u001b[39m \u001b[43mrelevance_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrelevance_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     features \u001b[38;5;241m=\u001b[39m relevance[relevance\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m    100\u001b[0m     relevance \u001b[38;5;241m=\u001b[39m relevance\u001b[38;5;241m.\u001b[39mloc[features]\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mrmr\\pandas.py:49\u001b[0m, in \u001b[0;36mf_regression\u001b[1;34m(X, y, n_jobs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_regression\u001b[39m(X, y, n_jobs):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_f_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mrmr\\pandas.py:17\u001b[0m, in \u001b[0;36mparallel_df\u001b[1;34m(func, df, series, n_jobs)\u001b[0m\n\u001b[0;32m     15\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(cpu_count(), \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)) \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(cpu_count(), n_jobs)\n\u001b[0;32m     16\u001b[0m col_chunks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)), n_jobs)\n\u001b[1;32m---> 17\u001b[0m lst \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_chunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_chunks\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(lst)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mrmr\n",
    "selected_features_mrmr=mrmr_regression(X=x_train,\n",
    "                                  y=y_train,\n",
    "                                  K=x_train.shape[1])\n",
    "\n",
    "mrmr_rank=pd.DataFrame(selected_features_mrmr).sort_values(by=0)\n",
    "mrmr_rank=pd.Series(mrmr_rank.index.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mutual info\n",
    "mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)\n",
    "\n",
    "mi_rank_df=pd.DataFrame(mi_scores).rank(ascending=False)\n",
    "mi_rank=pd.Series(mi_rank_df.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F test\n",
    "f_score,_=f_regression(x_train,y_train)\n",
    "f_score_rank_df=pd.DataFrame(f_score).rank(ascending=False)\n",
    "f_rank=pd.Series(f_score_rank_df.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLS sequential maybe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_svm_sequential=show_imp(X,svr_sequential_rank,200)\n",
    "test_svm_perm_imp=show_imp(X,importance_overall_rank_svm,200)\n",
    "test_mi=show_imp(X,mi_rank,200)\n",
    "test_mrmr=show_imp(X,mrmr_rank,200)\n",
    "\n",
    "pls=show_imp(x_train,importance_overall_rank_pls,200)\n",
    "svm=show_imp(x_train,importance_overall_rank_svm,200)\n",
    "nn=show_imp(x_train,importance_overall_rank_nn,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array([pls,svm,nn])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['PLS','SVR','ANN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array([test_svm_sequential,test_svm_perm_imp,test_mi,test_mrmr])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['sequential','permutation','MI','mrmr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pls_100=show_imp(X,importance_overall_rank_pls,100)\n",
    "test_pls_200=show_imp(X,importance_overall_rank_pls,200)\n",
    "test_nn_100=show_imp(X,importance_overall_rank_nn,100)\n",
    "test_nn_200=show_imp(X,importance_overall_rank_nn,200)\n",
    "test_mrmr_100=show_imp(X,mrmr_rank,100)\n",
    "test_mrmr_200=show_imp(X,mrmr_rank,200)\n",
    "test_mi_100=show_imp(X,mi_rank,100)\n",
    "test_mi_200=show_imp(X,mi_rank,200)\n",
    "test_f_100=show_imp(X,f_rank,100)\n",
    "test_f_200=show_imp(X,f_rank,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proximos, Fscore junto de mi e mrmr\n",
    "\n",
    "#colocar mrmr mi e pls junto p ex. e referir a parte de que podem ter varias solues optimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array([test_pls_200,test_pls_100,test_nn_200,test_nn_100,test_mrmr_200,test_mrmr_100,test_mi_200,test_mi_100,test_f_200,test_f_100])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['PI_pls_200','PI_pls_100','PI_nn_200','PI_nn_100','mrmr_200','mrmr_100','mi_200','mi_100','f_test_200','f_test_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array([test_pls_200,\n",
    "                test_pls_100,\n",
    "                test_nn_200,\n",
    "                test_nn_100,\n",
    "                test_mrmr_200,\n",
    "                test_mrmr_100,\n",
    "                test_mi_200,\n",
    "                test_mi_100,\n",
    "                test_f_200,\n",
    "                test_f_100])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['PI_pls_200',\n",
    "                                   'PI_pls_100',\n",
    "                                   'PI_nn_200',\n",
    "                                   'PI_nn_100',\n",
    "                                   'mrmr_200',\n",
    "                                   'mrmr_100',\n",
    "                                   'mi_200',\n",
    "                                   'mi_100',\n",
    "                                   'f_test_200',\n",
    "                                   'f_test_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_400=show_imp(X,mi_rank,400)\n",
    "mi_300=show_imp(X,mi_rank,300)\n",
    "mi_200=show_imp(X,mi_rank,200)\n",
    "mi_100=show_imp(X,mi_rank,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array([mi_100,\n",
    "                mi_200,\n",
    "                mi_300,\n",
    "                mi_400])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['MI_100',\n",
    "                                   'MI_200',\n",
    "                                   'MI_300',\n",
    "                                   'MI_400'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLS_PI_200=show_imp(X,importance_overall_rank_pls,100) #not actual 200\n",
    "SVM_PI_200=show_imp(X,importance_overall_rank_svm,100)\n",
    "NN_PI_200=show_imp(X,importance_overall_rank_nn,100)\n",
    "\n",
    "array=np.array([PLS_PI_200,\n",
    "                SVM_PI_200,\n",
    "                NN_PI_200])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['PLS',\n",
    "                                   'SVR',\n",
    "                                   'ANN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI mrmr and f\n",
    "\n",
    "mi=show_imp(x_train,mi_rank,400) #not actual 200\n",
    "mrmr=show_imp(x_train,mrmr_rank,400)\n",
    "f=show_imp(x_train,f_rank,400)\n",
    "\n",
    "array=np.array([mi,\n",
    "                mrmr,\n",
    "                f])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['MI',\n",
    "                                   'mRMR',\n",
    "                                   'F-test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLS and PI\n",
    "\n",
    "mi_300=show_imp(X,mi_rank,300)\n",
    "mi_200=show_imp(X,mi_rank,200)\n",
    "mi_100=show_imp(X,mi_rank,100)\n",
    "\n",
    "\n",
    "array=np.array([mi_100,\n",
    "                mi_200,\n",
    "                mi_300,])\n",
    "array=array.astype(int)\n",
    "data=pd.DataFrame(array.T,columns=['100',\n",
    "                                   '200',\n",
    "                                   '300'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(4.5, 7))  # Adjusted figure size\n",
    "\n",
    "# Create a custom colormap with the specified colors\n",
    "cmap = sns.color_palette([\"#fdffe3\", \"#1d462c\"], as_cmap=True)\n",
    "\n",
    "# Create a custom legend\n",
    "legend_elements = [plt.Rectangle((0, 0), 1, 1, facecolor=\"#1d462c\", edgecolor='none', label='Selected'),\n",
    "                   plt.Rectangle((0, 0), 1, 1, facecolor=\"#fdffe3\", edgecolor='none', label='Not Selected')]\n",
    "\n",
    "sns.heatmap(data, annot=False, cmap=cmap, cbar=False)\n",
    "plt.xlabel('\\# Features Selected by MI', fontsize=16)\n",
    "plt.ylabel('Wave Number', fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "# Add the custom legend to the plot at the bottom\n",
    "plt.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=2, fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the plot spacing\n",
    "\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\first.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the science plot style\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(10, 10))  # Adjusted figure size for better clarity\n",
    "\n",
    "sns.heatmap(data, annot=False, cmap=\"YlGn\")\n",
    "plt.title('Top N feature selected among different methods')\n",
    "plt.xlabel('Method_bestN')\n",
    "plt.ylabel('Wave number')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS muatual info best n_components for top_n variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pls_mutual_info_find_best(x_train, y_train, x_test, y_test, step, k_folds):\n",
    "    columns = ['top_n', 'CV', 'CV_std', 'train', 'test mse', 'n_components']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "   \n",
    "    mi_scores = mutual_info_regression(x_train, y_train, n_neighbors=3)\n",
    "   \n",
    "    for features in tqdm(np.arange(401, 20, -step)):\n",
    "        important_idx = pd.Series(mi_scores).sort_values(ascending=False).head(features).index.sort_values()\n",
    "       \n",
    "        x_train_important = x_train.iloc[:, important_idx].sort_index(axis=1)\n",
    "        x_test_important = x_test.iloc[:, important_idx].sort_index(axis=1)\n",
    "       \n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "       \n",
    "        best_CV = np.inf\n",
    "        best_n_components = 0\n",
    "        best_val_mse_folds = []\n",
    "       \n",
    "        for latent_variables in range(1, min(30,features)):\n",
    "            val_mse_fold = []\n",
    "           \n",
    "            for _, (train_idx, val_idx) in enumerate(kfold.split(x_train_important)):\n",
    "                train_idx_sorted = np.sort(train_idx)\n",
    "                val_idx_sorted = np.sort(val_idx)\n",
    "               \n",
    "                x_train_fold = x_train_important.iloc[train_idx_sorted]\n",
    "                y_train_fold = y_train.iloc[train_idx_sorted]\n",
    "                x_val_fold = x_train_important.iloc[val_idx_sorted]\n",
    "                y_val_fold = y_train.iloc[val_idx_sorted]\n",
    "               \n",
    "                pls = PLSRegression(n_components=latent_variables)\n",
    "                pls.fit(x_train_fold, y_train_fold)\n",
    "               \n",
    "                val_loss_single_fold = mean_squared_error(y_val_fold, pls.predict(x_val_fold))\n",
    "                val_mse_fold.append(val_loss_single_fold)\n",
    "           \n",
    "            avg_loss_val_fold = np.mean(val_mse_fold)\n",
    "           \n",
    "            if avg_loss_val_fold < best_CV:\n",
    "                best_CV = avg_loss_val_fold\n",
    "                best_n_components = latent_variables\n",
    "                best_val_mse_folds = val_mse_fold\n",
    "               \n",
    "        cv_std = np.std(best_val_mse_folds)\n",
    "       \n",
    "        pls = PLSRegression(n_components=best_n_components)\n",
    "        pls.fit(x_train_important, y_train)\n",
    "       \n",
    "        train_loss = mean_squared_error(y_train, pls.predict(x_train_important))\n",
    "        test_loss = mean_squared_error(y_test, pls.predict(x_test_important))\n",
    "       \n",
    "        stored.loc[features] = [features, best_CV, cv_std, train_loss, test_loss, best_n_components]\n",
    "       \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pls_mutual_info_find_best(x_train=x_train,\n",
    "                                 y_train=y_train,\n",
    "                                 x_test=x_test,\n",
    "                                 y_test=y_test,\n",
    "                                 step=10,\n",
    "                                 k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table['top_n'], table['train'], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table['top_n'], table['test mse'], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table['top_n'], table['CV'], yerr=table['CV_std'], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_MI_variable.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'table_top_n__best_n_components_pls_mutual_info_150_to_1')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"C:\\\\Users\\\\lucas\\\\Downloads\\\\table_top_n__best_n_components_pls_mutual_info.csv\")\n",
    "df2=pd.read_csv(\"C:\\\\Users\\\\lucas\\\\Downloads\\\\table_top_n__best_n_components_pls_mutual_info_150_to_1.csv\")\n",
    "table=pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(df2['top_n'], df2['train'], color='C0', marker='o', label='train')\n",
    "plt.scatter(df1['top_n'], df1['train'], color='C0', marker='o')\n",
    "\n",
    "plt.scatter(df2['top_n'], df2['test mse'], color='C2', marker='o', label='test')\n",
    "plt.scatter(df1['top_n'], df1['test mse'], color='C2', marker='o')\n",
    "\n",
    "plt.scatter(df2['top_n'], df2['CV'], color='C1', marker='o', label='CV')\n",
    "plt.scatter(df1['top_n'], df1['CV'], color='C1', marker='o')\n",
    "\n",
    "plt.ylim(0,0.4)\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('best_n variables')\n",
    "plt.title('PLS mutual information best n_components best_n variables')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(df2['top_n'], df2['n_components'], color='C0', marker='o')\n",
    "plt.scatter(df1['top_n'], df1['n_components'], color='C0', marker='o')\n",
    "\n",
    "plt.ylim(0,50)\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.ylabel('best n_components')\n",
    "plt.xlabel('best_n variables')\n",
    "plt.title('PLS mutual information best n_components best_n variables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_mutual_info_svm(x_train, y_train, x_test, y_test, step, k_folds, latent_variables):\n",
    "    np.random.seed(42)\n",
    "    columns = ['train mse', 'train std', 'val mse', 'val std', 'calibration mse', 'test mse',\n",
    "               'r2_cal', 'r2_test', 'r2_cv', 'r2_cv_std']\n",
    "    \n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # Compute mutual information scores\n",
    "    mi_scores = mutual_info_regression(x_train, y_train, n_neighbors=3)\n",
    "    feature_indices = pd.Series(mi_scores).sort_values(ascending=False).index\n",
    "    \n",
    "    for features in np.arange(401, 399, -step):\n",
    "        # Select the top 'features' based on mutual information scores\n",
    "        important_idx = feature_indices[:features]\n",
    "        # Use the important indices to subset the features\n",
    "        x_train_filtered = x_train.iloc[:, important_idx]\n",
    "        x_test_filtered = x_test.iloc[:, important_idx]\n",
    "        # Setup cross-validation\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "        r2_CV_folds = []\n",
    "        \n",
    "        for train_idx, val_idx in kfold.split(x_train_filtered):\n",
    "            x_train_fold = x_train_filtered.iloc[train_idx]\n",
    "            y_train_fold = y_train.iloc[train_idx]\n",
    "            x_val_fold = x_train_filtered.iloc[val_idx]\n",
    "            y_val_fold = y_train.iloc[val_idx]\n",
    "            # Train the model on the training fold\n",
    "            svm = SVR(kernel='linear')\n",
    "            svm.fit(x_train_fold, y_train_fold)\n",
    "            # Compute MSE and R-squared for the training and validation folds\n",
    "            train_loss_single_fold = mean_squared_error(y_train_fold, svm.predict(x_train_fold))\n",
    "            val_loss_single_fold = mean_squared_error(y_val_fold, svm.predict(x_val_fold))\n",
    "            single_fold_val = r2_score(y_val_fold, svm.predict(x_val_fold))\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "            r2_CV_folds.append(single_fold_val)\n",
    "            \n",
    "        # Train and evaluate the model on the complete train and test datasets\n",
    "        svm_full = SVR(kernel='linear')\n",
    "        svm_full.fit(x_train_filtered, y_train)\n",
    "        train_loss = mean_squared_error(y_train, svm_full.predict(x_train_filtered))\n",
    "        test_loss = mean_squared_error(y_test, svm_full.predict(x_test_filtered))\n",
    "        train_loss_r2 = r2_score(y_train, svm_full.predict(x_train_filtered))\n",
    "        test_loss_r2 = r2_score(y_test, svm_full.predict(x_test_filtered))\n",
    "        \n",
    "        # Store results\n",
    "        stored.loc[features] = [\n",
    "            np.mean(train_mse_fold), np.std(train_mse_fold),\n",
    "            np.mean(val_mse_fold), np.std(val_mse_fold),\n",
    "            train_loss, test_loss,\n",
    "            train_loss_r2, test_loss_r2,\n",
    "            np.mean(r2_CV_folds), np.std(r2_CV_folds)\n",
    "        ]\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mutual_info_svm(x_train, y_train, x_test, y_test, 1, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV MSE', color='green', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['calibration mse'][::-1], yerr=0, fmt='s', markersize=5, label='Calibration MSE', color='red', alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['test mse'][::-1], yerr=0, fmt='d', markersize=5, label='Test MSE', color='orange', alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top x features', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14)\n",
    "plt.title('MSE and Variance over top n features', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4)\n",
    "plt.ylim(0.01,0.2)\n",
    "plt.gca().invert_xaxis()  # Keep the x-axis inverted\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate permutation importance, evaluate on every fold, also stores learning curves...\n",
    "def permutation_importance_svm(X_train,y_train,k_folds):\n",
    "    \n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        try:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas DataFrame.\")\n",
    "    \n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        try:\n",
    "            y_train = pd.Series(y_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas Series.\")        \n",
    "               \n",
    "    kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "\n",
    "    cross_importances=np.zeros((x_train.shape[1],kfold.n_splits))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "        x_train_fold=X_train.iloc[np.sort(train_idx)]\n",
    "        y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "        x_val_fold=X_train.iloc[np.sort(val_idx)]\n",
    "        y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "        \n",
    "        svm=SVR(kernel='linear')\n",
    "        svm.fit(x_train_fold,y_train_fold)\n",
    "        \n",
    "        results = permutation_importance(svm,\n",
    "                                        x_val_fold,\n",
    "                                        y_val_fold,\n",
    "                                        n_repeats=30,\n",
    "                                        random_state=42,\n",
    "                                        n_jobs=4,\n",
    "                                        scoring='neg_mean_squared_error')\n",
    "        \n",
    "        cross_importances[:,fold]=results.importances_mean\n",
    "        \n",
    "    return cross_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_svm(x_train,y_train,x_test,y_test,step,perm_imp_array,k_folds):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for features in np.arange(401,1,-step):\n",
    "        \n",
    "        important_idx=perm_imp_get_topn_indexes(perm_imp_output=perm_imp_array,\n",
    "                                                top_n=features)\n",
    "    \n",
    "        x_train_reduced=x_train[important_idx.sort_values()]\n",
    "        x_test_reduced=x_test[important_idx.sort_values()]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_reduced)):\n",
    "        \n",
    "            x_train_fold=x_train_reduced.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train_reduced.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            svm=SVR(kernel='linear')\n",
    "            svm.fit(x_train_fold,y_train_fold)\n",
    "            \n",
    "            train_loss_single_fold=mean_squared_error(y_train_fold,svm.predict(x_train_fold))\n",
    "            val_loss_single_fold=mean_squared_error(y_val_fold,svm.predict(x_val_fold))\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "\n",
    "        svm=SVR(kernel='linear')\n",
    "        svm.fit(x_train_reduced,y_train)\n",
    "        \n",
    "        train_loss=mean_squared_error(y_train,svm.predict(x_train_reduced))\n",
    "        test_loss=mean_squared_error(y_test,svm.predict(x_test_reduced))\n",
    "    \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_svm=permutation_importance_svm(X_train=x_train,\n",
    "                                           y_train=y_train,\n",
    "                                           k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rank=pd.DataFrame(importances_svm).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "importance_overall_rank_svm=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_intersections(importance_rank_named,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table= build_table_svm(x_train=x_train,\n",
    "                        y_train=y_train,\n",
    "                       x_test=x_test,\n",
    "                       y_test=y_test,\n",
    "                       step=100,\n",
    "                       perm_imp_array=importance_overall_rank_svm,\n",
    "                       k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM mrmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_mrmr_svm(x_train, y_train, x_test, y_test, step, k_folds):\n",
    "    np.random.seed(42)\n",
    "    columns = ['train mse', 'train std', 'val mse', 'val std', 'calibration mse', 'test mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Compute mutual information scores\n",
    "    selected_features = mrmr_regression(X=x_train, y=y_train, K=401)\n",
    "    \n",
    "    for features in tqdm(np.arange(401, 20, -step)):\n",
    "        important_idx = selected_features[0:features]\n",
    "\n",
    "        # Use the important indices to subset the features\n",
    "        x_train_filtered = x_train.iloc[:, important_idx]\n",
    "        x_test_filtered = x_test.iloc[:, important_idx]\n",
    "\n",
    "        # Setup cross-validation\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(x_train_filtered):\n",
    "            x_train_fold = x_train_filtered.iloc[train_idx]\n",
    "            y_train_fold = y_train.iloc[train_idx].values  # Ensure y_train_fold is an array\n",
    "            x_val_fold = x_train_filtered.iloc[val_idx]\n",
    "            y_val_fold = y_train.iloc[val_idx].values  # Ensure y_val_fold is an array\n",
    "            \n",
    "            # Train the model on the training fold\n",
    "            svm = SVR(kernel='linear')\n",
    "            svm.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "            # Compute MSE for the training and validation folds\n",
    "            train_loss_single_fold = mean_squared_error(y_train_fold, svm.predict(x_train_fold))\n",
    "            val_loss_single_fold = mean_squared_error(y_val_fold, svm.predict(x_val_fold))\n",
    "\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "\n",
    "        # Train and evaluate the model on the complete train and test datasets\n",
    "        svm_full = SVR(kernel='linear')\n",
    "        svm_full.fit(x_train_filtered, y_train.values)  # Ensure y_train is an array\n",
    "        train_loss = mean_squared_error(y_train.values, svm_full.predict(x_train_filtered))\n",
    "        test_loss = mean_squared_error(y_test.values, svm_full.predict(x_test_filtered))  # Ensure y_test is an array\n",
    "\n",
    "        # Store results\n",
    "        stored.loc[features] = [\n",
    "            np.mean(train_mse_fold), np.std(train_mse_fold),\n",
    "            np.mean(val_mse_fold), np.std(val_mse_fold),\n",
    "            train_loss, test_loss\n",
    "        ]\n",
    "\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_mrmr_svm(x_train, y_train, x_test, y_test, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-1], table['calibration mse'][::-1], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-1], table['test mse'][::-1], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-1], table['val mse'][::-1], yerr=table['val std'][::-1], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\SVM_mrmr.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_MI_svm(x_train, y_train, x_test, y_test, step, k_folds):\n",
    "    np.random.seed(42)\n",
    "    columns = ['train mse', 'train std', 'CV r2', 'CV stdev', 'calibration r2', 'test r2']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Compute mutual information scores\n",
    "    mi_scores=mutual_info_regression(x_train,y_train,n_neighbors=3)\n",
    "    \n",
    "    for features in tqdm(np.arange(401, 30, -step)):\n",
    "        \n",
    "        important_idx=pd.Series(mi_scores).sort_values(ascending=False).head(features).index\n",
    "\n",
    "        # Use the important indices to subset the features\n",
    "        x_train_filtered = x_train.iloc[:, important_idx]\n",
    "        x_test_filtered = x_test.iloc[:, important_idx]\n",
    "\n",
    "        # Setup cross-validation\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        train_mse_fold = []\n",
    "        val_mse_fold = []\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(x_train_filtered):\n",
    "            x_train_fold = x_train_filtered.iloc[train_idx]\n",
    "            y_train_fold = y_train.iloc[train_idx]\n",
    "            x_val_fold = x_train_filtered.iloc[val_idx]\n",
    "            y_val_fold = y_train.iloc[val_idx]\n",
    "            \n",
    "            # Train the model on the training fold\n",
    "            svm = SVR(kernel='linear')\n",
    "            svm.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "            # Compute MSE for the training and validation folds\n",
    "            train_loss_single_fold = r2_score(y_train_fold, svm.predict(x_train_fold))\n",
    "            val_loss_single_fold = r2_score(y_val_fold, svm.predict(x_val_fold))\n",
    "\n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "\n",
    "        # Train and evaluate the model on the complete train and test datasets\n",
    "        svm_full = SVR(kernel='linear')\n",
    "        svm_full.fit(x_train_filtered, y_train)\n",
    "        train_loss = r2_score(y_train, svm_full.predict(x_train_filtered))\n",
    "        test_loss = r2_score(y_test, svm_full.predict(x_test_filtered))\n",
    "\n",
    "        # Store results\n",
    "        stored.loc[features] = [\n",
    "            np.mean(train_mse_fold), np.std(train_mse_fold),\n",
    "            np.mean(val_mse_fold), np.std(val_mse_fold),\n",
    "            train_loss, test_loss\n",
    "        ]\n",
    "\n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=build_table_MI_svm(x_train=x_train,\n",
    "                         y_train=y_train,\n",
    "                         x_test=x_test,\n",
    "                         y_test=y_test,\n",
    "                         step=10,\n",
    "                         k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['CV r2'][::-1], yerr=table['CV stdev'][::-1], fmt='^', markersize=5, capsize=2, label='CV r2', color='green', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['calibration r2'][::-1], yerr=0, fmt='s', markersize=5, label='Calibration r2', color='red', alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['test r2'][::-1], yerr=0, fmt='d', markersize=5, label='Test r2', color='orange', alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top x features', fontsize=14)\n",
    "plt.ylabel('R2', fontsize=14)\n",
    "plt.title('R2 and Variance over top n features', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4)\n",
    "plt.ylim(0.65,1)\n",
    "plt.gca().invert_xaxis()  # Keep the x-axis inverted\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate permutation importance, evaluate on every fold, also stores learning curves...\n",
    "def permutation_importance_svm(X_train,y_train,k_folds):\n",
    "    \n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        try:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas DataFrame.\")\n",
    "    \n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        try:\n",
    "            y_train = pd.Series(y_train)\n",
    "        except ValueError:\n",
    "            print(\"X cannot be converted to a pandas Series.\")        \n",
    "               \n",
    "    kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "\n",
    "    cross_importances=np.zeros((x_train.shape[1],kfold.n_splits))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "        x_train_fold=X_train.iloc[np.sort(train_idx)]\n",
    "        y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "        x_val_fold=X_train.iloc[np.sort(val_idx)]\n",
    "        y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "        \n",
    "        svm=SVR(kernel='linear')\n",
    "        svm.fit(x_train_fold,y_train_fold)\n",
    "        \n",
    "        results = permutation_importance(svm,\n",
    "                                        x_val_fold,\n",
    "                                        y_val_fold,\n",
    "                                        n_repeats=30,\n",
    "                                        random_state=42,\n",
    "                                        n_jobs=4,\n",
    "                                        scoring='neg_mean_squared_error')\n",
    "        \n",
    "        cross_importances[:,fold]=results.importances_mean\n",
    "        \n",
    "    return cross_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_pls(x_train,y_train,x_test,y_test,step,perm_imp_array,k_folds,latent_variables):\n",
    "    #here i used the terms calibration and train somewhat interchangeably\n",
    "    #the idea is that the complete train set without fold separation to be called calibration\n",
    "    #the fold used to generate the model is train and the fold used to validade is validation...\n",
    "    columns=['train mse','train std','val mse','val std','calibration mse','test mse']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for features in np.arange(401,399,-step):\n",
    "        \n",
    "        important_idx=perm_imp_get_topn_indexes(perm_imp_output=perm_imp_array,\n",
    "                                                top_n=features)\n",
    "    \n",
    "        x_train_reduced=x_train[important_idx.sort_values()]\n",
    "        x_test_reduced=x_test[important_idx.sort_values()]\n",
    "        \n",
    "        kfold=KFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "        \n",
    "        train_mse_fold=[]\n",
    "        val_mse_fold=[]\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_reduced)):\n",
    "        \n",
    "            x_train_fold=x_train_reduced.iloc[np.sort(train_idx)]\n",
    "            y_train_fold=y_train.iloc[np.sort(train_idx)]\n",
    "            x_val_fold=x_train_reduced.iloc[np.sort(val_idx)]\n",
    "            y_val_fold=y_train.iloc[np.sort(val_idx)]\n",
    "            \n",
    "            pls=PLSRegression(n_components=latent_variables)\n",
    "            pls.fit(x_train_fold,y_train_fold)\n",
    "            \n",
    "            train_loss_single_fold=mean_squared_error(y_train_fold,pls.predict(x_train_fold))\n",
    "            val_loss_single_fold=mean_squared_error(y_val_fold,pls.predict(x_val_fold))\n",
    "            \n",
    "            train_mse_fold.append(train_loss_single_fold)\n",
    "            val_mse_fold.append(val_loss_single_fold)\n",
    "        \n",
    "\n",
    "        pls=PLSRegression(n_components=latent_variables)\n",
    "        pls.fit(x_train_reduced,y_train)\n",
    "        \n",
    "        train_loss=mean_squared_error(y_train,pls.predict(x_train_reduced))\n",
    "        test_loss=mean_squared_error(y_test,pls.predict(x_test_reduced))\n",
    "    \n",
    "        #['avg train mse','std train mse,'avg val mse','std val mse','calibration mse','test mse']\n",
    "        avg_loss_train_fold=np.mean(train_mse_fold)\n",
    "        std_loss_train_fold=np.std(train_mse_fold)\n",
    "        avg_loss_val_fold=np.mean(val_mse_fold)\n",
    "        std_loss_val_fold=np.std(val_mse_fold)\n",
    "        \n",
    "        stored.loc[features] = [avg_loss_train_fold,\n",
    "                                std_loss_train_fold,\n",
    "                                avg_loss_val_fold,\n",
    "                                std_loss_val_fold,\n",
    "                                train_loss,\n",
    "                                test_loss]\n",
    "            \n",
    "    return stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_svm=permutation_importance_svm(X_train=x_train,\n",
    "                                           y_train=y_train,\n",
    "                                           k_folds=5)\n",
    "importance_rank=pd.DataFrame(importances_svm).rank(ascending=False)\n",
    "importance_rank_named=importance_rank.rename(columns={0:'fold1',1:'fold2',2:'fold3',3:'fold4',4:'fold5'})\n",
    "#importance_overall_rank=importance_rank_named.mean(axis=1)\n",
    "importance_overall_rank_svm=importance_rank_named.median(axis=1) #using median is more robust to outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLS sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_cross_val_score(X, y, n_components, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        \n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        \n",
    "        pls = PLSRegression(n_components=n_components)\n",
    "        pls.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = pls.predict(X_val_fold)\n",
    "        r2 = r2_score(y_val_fold, y_val_pred)\n",
    "        r2_scores.append(r2)\n",
    "    return np.mean(r2_scores), r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_next_index_and_cv(X_train, y_train, already_selected, n_components):\n",
    "    best_cv = 0\n",
    "    feature_to_enter = None\n",
    "    best_cv_list = None\n",
    "\n",
    "    for feature in range(X_train.shape[1]):\n",
    "        if feature not in already_selected:\n",
    "            indexes = already_selected + [feature]\n",
    "            x_train_sliced = X_train[:, indexes]\n",
    "\n",
    "            if x_train_sliced.ndim == 1:\n",
    "                x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "\n",
    "            cv, cv_list = pls_cross_val_score(X=x_train_sliced,\n",
    "                                              y=y_train,\n",
    "                                              n_components=n_components,\n",
    "                                              cv=5)\n",
    "            if np.mean(cv_list) >= best_cv:\n",
    "                best_cv = cv\n",
    "                feature_to_enter = feature\n",
    "                best_cv_list = cv_list\n",
    "\n",
    "    return best_cv, feature_to_enter, best_cv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_feature_selection(X_train, y_train, X_test, y_test, pre_use_indexes):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    columns = ['CV r2', 'CV stdev', 'calibration r2', 'test r2', 'n_components', 'n_features']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "    selected_indexes = pre_use_indexes\n",
    "\n",
    "    for n_features in tqdm(range(1, 201)):\n",
    "        if n_features <= 20:\n",
    "            n_components = n_features\n",
    "        else:\n",
    "            n_components = 20\n",
    "\n",
    "        best_cv, feature_to_enter, best_cv_list = return_next_index_and_cv(X_train=X_train,\n",
    "                                                                           y_train=y_train,\n",
    "                                                                           already_selected=selected_indexes,\n",
    "                                                                           n_components=n_components)\n",
    "\n",
    "        selected_indexes.append(feature_to_enter)\n",
    "\n",
    "        x_train_sliced = X_train[:, selected_indexes]\n",
    "        x_test_sliced = X_test[:, selected_indexes]\n",
    "\n",
    "        if x_train_sliced.ndim == 1:\n",
    "            x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "\n",
    "        pls = PLSRegression(n_components=n_components)\n",
    "        pls.fit(x_train_sliced, y_train)\n",
    "        train_loss = r2_score(y_train, pls.predict(x_train_sliced))\n",
    "        test_loss = r2_score(y_test, pls.predict(x_test_sliced))\n",
    "\n",
    "        # Store results\n",
    "        stored.loc[n_features] = [np.mean(best_cv_list),\n",
    "                                  np.std(best_cv_list),\n",
    "                                  train_loss,\n",
    "                                  test_loss,\n",
    "                                  n_components,\n",
    "                                  n_features]\n",
    "\n",
    "    return stored, selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_cross_val_score(X, y, n_components, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        \n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        \n",
    "        pls = PLSRegression(n_components=n_components)\n",
    "        pls.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = pls.predict(X_val_fold)\n",
    "        mse = mean_squared_error(y_val_fold, y_val_pred)\n",
    "        mse_scores.append(mse)\n",
    "    return np.mean(mse_scores), mse_scores\n",
    "\n",
    "def return_next_index_and_cv(X_train, y_train, already_selected, n_components):\n",
    "    best_cv = float('inf')\n",
    "    feature_to_enter = None\n",
    "    best_cv_list = None\n",
    "\n",
    "    for feature in range(X_train.shape[1]):\n",
    "        if feature not in already_selected:\n",
    "            indexes = already_selected + [feature]\n",
    "            x_train_sliced = X_train[:, indexes]\n",
    "\n",
    "            if x_train_sliced.ndim == 1:\n",
    "                x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "\n",
    "            cv, cv_list = pls_cross_val_score(X=x_train_sliced,\n",
    "                                              y=y_train,\n",
    "                                              n_components=n_components,\n",
    "                                              cv=5)\n",
    "            if np.mean(cv_list) <= best_cv:\n",
    "                best_cv = cv\n",
    "                feature_to_enter = feature\n",
    "                best_cv_list = cv_list\n",
    "\n",
    "    return best_cv, feature_to_enter, best_cv_list\n",
    "\n",
    "def sequential_feature_selection(X_train, y_train, X_test, y_test, pre_use_indexes):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    columns = ['CV MSE', 'CV stdev', 'calibration MSE', 'test MSE', 'n_components', 'n_features']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "    selected_indexes = pre_use_indexes\n",
    "\n",
    "    for n_features in tqdm(range(1, 201)):\n",
    "        if n_features <= 20:\n",
    "            n_components = n_features\n",
    "        else:\n",
    "            n_components = 20\n",
    "\n",
    "        best_cv, feature_to_enter, best_cv_list = return_next_index_and_cv(X_train=X_train,\n",
    "                                                                           y_train=y_train,\n",
    "                                                                           already_selected=selected_indexes,\n",
    "                                                                           n_components=n_components)\n",
    "\n",
    "        selected_indexes.append(feature_to_enter)\n",
    "\n",
    "        x_train_sliced = X_train[:, selected_indexes]\n",
    "        x_test_sliced = X_test[:, selected_indexes]\n",
    "\n",
    "        if x_train_sliced.ndim == 1:\n",
    "            x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "\n",
    "        pls = PLSRegression(n_components=n_components)\n",
    "        pls.fit(x_train_sliced, y_train)\n",
    "        train_loss = mean_squared_error(y_train, pls.predict(x_train_sliced))\n",
    "        test_loss = mean_squared_error(y_test, pls.predict(x_test_sliced))\n",
    "\n",
    "        # Store results\n",
    "        stored.loc[n_features] = [np.mean(best_cv_list),\n",
    "                                  np.std(best_cv_list),\n",
    "                                  train_loss,\n",
    "                                  test_loss,\n",
    "                                  n_components,\n",
    "                                  n_features]\n",
    "\n",
    "    return stored, selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "selected_indexes = list(indexes)  # List with the order of features that should be added\n",
    "results = evaluate_feature_selection(X_train=x_train, \n",
    "                                     y_train=y_train, \n",
    "                                     X_test=x_test, \n",
    "                                     y_test=y_test, \n",
    "                                     selected_indexes=selected_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table,indexes=sequential_feature_selection(X_train=x_train, \n",
    "                                           y_train=y_train,\n",
    "                                           X_test=x_test,\n",
    "                                           y_test=y_test,\n",
    "                                           pre_use_indexes=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(table)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'PLS_sequential_up_to_200.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_sequential_up_to_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.scatter(table.index[::-5], table['calibration MSE'][::-5], marker='s', s=25, label='train', color='C1', alpha=0.7)\n",
    "plt.scatter(table.index[::-5], table['test MSE'][::-5], marker='d', s=25, label='test', color='C0', alpha=0.7)\n",
    "plt.errorbar(table.index[::-5], table['CV MSE'][::-5], yerr=table['CV stdev'][::-5], fmt='^', markersize=5, capsize=2, label='CV', color='C2', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top Ranking Features', fontsize=24)\n",
    "plt.ylabel('MSE', fontsize=24)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4,fontsize=24)\n",
    "plt.ylim(0.01,0.2)\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\lucas\\\\Downloads\\\\SFS_PLS_20.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cross_val_score(X, y, cv=5):\n",
    "    \n",
    "    kf = KFold(n_splits=cv,shuffle=True,random_state=42)\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        svm = SVR(kernel='linear')\n",
    "        svm.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = svm.predict(X_val_fold)\n",
    "        r2 = r2_score(y_val_fold, y_val_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    return np.mean(r2_scores),r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_next_index_and_cv(X_train,y_train,already_selected):\n",
    "    best_cv=0\n",
    "    feature_to_enter=None\n",
    "    best_n_components=None\n",
    "    best_cv_list=None\n",
    "    \n",
    "    for feature in range(X_train.shape[1]):\n",
    "        if feature not in already_selected:\n",
    "            indexes=already_selected+[feature]\n",
    "            x_train_sliced=X_train[:,indexes]\n",
    "            \n",
    "            if x_train_sliced.ndim == 1:\n",
    "                x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "                \n",
    "            cv,cv_list=svm_cross_val_score(X=x_train_sliced,\n",
    "                                           y=y_train, \n",
    "                                           cv=5)\n",
    "\n",
    "            if np.mean(cv_list)>=best_cv:\n",
    "                best_cv=cv\n",
    "                feature_to_enter=feature\n",
    "                best_cv_list=cv_list\n",
    "            \n",
    "    return best_cv,feature_to_enter,best_cv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_feature_selection(X_train, y_train, X_test, y_test, pre_use_indexes):\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    columns = ['CV MSE', 'CV stdev', 'calibration MSE', 'test MSE', 'n_features']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    selected_indexes = pre_use_indexes\n",
    "    for n_features in tqdm(range(1, 8)):\n",
    "        best_cv, feature_to_enter, best_cv_list = return_next_index_and_cv(X_train=X_train,\n",
    "                                                                           y_train=y_train,\n",
    "                                                                           already_selected=selected_indexes)\n",
    "        \n",
    "        selected_indexes.append(feature_to_enter)\n",
    "        \n",
    "        x_train_sliced = X_train[:, selected_indexes]\n",
    "        x_test_sliced = X_test[:, selected_indexes]\n",
    "        \n",
    "        if x_train_sliced.ndim == 1:\n",
    "            x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "            \n",
    "        svm = SVR(kernel='linear')\n",
    "        svm.fit(x_train_sliced, y_train)\n",
    "        train_loss = mean_squared_error(y_train, svm.predict(x_train_sliced))\n",
    "        test_loss = mean_squared_error(y_test, svm.predict(x_test_sliced))\n",
    "        \n",
    "        # Store results\n",
    "        stored.loc[n_features] = [np.mean(best_cv_list),        \n",
    "                                  np.std(best_cv_list),\n",
    "                                  train_loss,\n",
    "                                  test_loss,\n",
    "                                  n_features]\n",
    "\n",
    "    return stored, selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cross_val_score(X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        svm = SVR(kernel='linear')\n",
    "        svm.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = svm.predict(X_val_fold)\n",
    "        mse = mean_squared_error(y_val_fold, y_val_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    return np.mean(mse_scores), mse_scores\n",
    "\n",
    "def return_next_index_and_cv(X_train, y_train, already_selected):\n",
    "    best_cv = float('inf')\n",
    "    feature_to_enter = None\n",
    "    best_cv_list = None\n",
    "    \n",
    "    for feature in range(X_train.shape[1]):\n",
    "        if feature not in already_selected:\n",
    "            indexes = already_selected + [feature]\n",
    "            x_train_sliced = X_train[:, indexes]\n",
    "            \n",
    "            if x_train_sliced.ndim == 1:\n",
    "                x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "                \n",
    "            cv, cv_list = svm_cross_val_score(X=x_train_sliced, y=y_train, cv=5)\n",
    "\n",
    "            if np.mean(cv_list) < best_cv:\n",
    "                best_cv = np.mean(cv_list)\n",
    "                feature_to_enter = feature\n",
    "                best_cv_list = cv_list\n",
    "            \n",
    "    return best_cv, feature_to_enter, best_cv_list\n",
    "\n",
    "def sequential_feature_selection(X_train, y_train, X_test, y_test, pre_use_indexes):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    columns = ['CV MSE', 'CV stdev', 'calibration MSE', 'test MSE', 'n_features']\n",
    "    stored = pd.DataFrame(columns=columns)\n",
    "\n",
    "    selected_indexes = pre_use_indexes\n",
    "    for n_features in tqdm(range(1, 200)):\n",
    "        best_cv, feature_to_enter, best_cv_list = return_next_index_and_cv(X_train=X_train,\n",
    "                                                                           y_train=y_train,\n",
    "                                                                           already_selected=selected_indexes)\n",
    "        \n",
    "        selected_indexes.append(feature_to_enter)\n",
    "        \n",
    "        x_train_sliced = X_train[:, selected_indexes]\n",
    "        x_test_sliced = X_test[:, selected_indexes]\n",
    "        \n",
    "        if x_train_sliced.ndim == 1:\n",
    "            x_train_sliced = x_train_sliced.reshape(-1, 1)\n",
    "            \n",
    "        svm = SVR(kernel='linear')\n",
    "        svm.fit(x_train_sliced, y_train)\n",
    "        train_loss = mean_squared_error(y_train, svm.predict(x_train_sliced))\n",
    "        test_loss = mean_squared_error(y_test, svm.predict(x_test_sliced))\n",
    "        \n",
    "        # Store results\n",
    "        stored.loc[n_features] = [np.mean(best_cv_list),        \n",
    "                                  np.std(best_cv_list),\n",
    "                                  train_loss,\n",
    "                                  test_loss,\n",
    "                                  n_features]\n",
    "\n",
    "    return stored, selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table,indexes=sequential_feature_selection(X_train=x_train, \n",
    "                                           y_train=y_train,\n",
    "                                           X_test=x_test,\n",
    "                                           y_test=y_test,\n",
    "                                           pre_use_indexes=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(\"C:\\\\Users\\\\lucas\\\\Downloads\\\\svr_here_here.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in memory...\n",
    "df=pd.DataFrame(indexesaa)\n",
    "dir_path='C:\\\\Users\\\\lucas\\\\Downloads'\n",
    "\n",
    "os.makedirs(dir_path,exist_ok=True)\n",
    "file_path=os.path.join(dir_path,'sequential_svm_order_up_to_199.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\PLS_sequential_1_to_29.csv')\n",
    "indexes=pd.read_csv('C:\\\\Users\\\\lucas\\\\Downloads\\\\sequential_svm_order_up_to_199.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size for better clarity\n",
    "\n",
    "#plt.errorbar(table.index[::-1], table['train mse'][::-1], yerr=table['train std'][::-1], fmt='o', markersize=5, capsize=2, label='Train MSE', color='blue', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['CV r2'][::-1], yerr=table['CV stdev'][::-1], fmt='^', markersize=5, capsize=2, label='CV r2', color='green', ecolor='gray', elinewidth=1, alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['calibration r2'][::-1], yerr=0, fmt='s', markersize=5, label='Calibration r2', color='red', alpha=0.7, linestyle='')\n",
    "plt.errorbar(table.index[::-1], table['test r2'][::-1], yerr=0, fmt='d', markersize=5, label='Test r2', color='orange', alpha=0.7, linestyle='')\n",
    "\n",
    "plt.xlabel('Top x features', fontsize=14)\n",
    "plt.ylabel('R2', fontsize=14)\n",
    "plt.title('R2 and Variance over top n features', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fancybox=True, shadow=True, ncol=4)\n",
    "plt.ylim(0.65,1)\n",
    "plt.gca().invert_xaxis()  # Keep the x-axis inverted\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_list=indexes.values.tolist()\n",
    "flat_list = [item for sublist in indexes_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,401):\n",
    "    if i not in flat_list:\n",
    "        flat_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
